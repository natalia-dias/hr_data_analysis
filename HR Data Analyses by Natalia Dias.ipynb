{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0729aa9",
   "metadata": {},
   "source": [
    "# HR Data Analysis #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26933e9a",
   "metadata": {},
   "source": [
    "### Learning outcomes ###\n",
    "\n",
    "\n",
    "Conduct data analysis and handle a case that resembles the actual tasks a data analyst may encounter at their job. Master data merging, grouping, aggregation functions, and draw up pivot tables using the pandas functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528dd7f",
   "metadata": {},
   "source": [
    "**Background:** \n",
    "\n",
    "You work as an analyst in a company. The company's HR boss provided you with three datasets. The first two contain information about employees' performance in offices A and B: how much they work, their salaries, the number of their projects, departments, and so on. The third one is an extensive dataset with information on the employees' satisfaction with their jobs, their latest evaluation metrics, and the current status in the company. Your task is to analyze the data and answer some of the HR’s questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4944b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "DATA_DIR = \"../Data\"\n",
    "A_FNAME = 'A_office_data.xml'\n",
    "B_FNAME = 'B_office_data.xml'\n",
    "HR_FNAME = 'hr_data.xml'\n",
    "SEP = '\\n' + '=' * 80 + '\\n'\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "\n",
    "\n",
    "def download_datasets():\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.mkdir(DATA_DIR)\n",
    "\n",
    "    # Download data if it is unavailable.\n",
    "    if (A_FNAME not in os.listdir(DATA_DIR) or\n",
    "            B_FNAME not in os.listdir(DATA_DIR) or\n",
    "            HR_FNAME not in os.listdir(DATA_DIR)):\n",
    "        print('A_office_data loading.')\n",
    "        url = f\"https://www.dropbox.com/s/jpeknyzx57c4jb2/{A_FNAME}?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(f\"{DATA_DIR}/{A_FNAME}\", 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('B_office_data loading.')\n",
    "        url = f\"https://www.dropbox.com/s/hea0tbhir64u9t5/{B_FNAME}?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(f\"{DATA_DIR}/{B_FNAME}\", 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        print('hr_data loading.')\n",
    "        url = f\"https://www.dropbox.com/s/u6jzqqg1byajy0s/{HR_FNAME}?dl=1\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(f\"{DATA_DIR}/{HR_FNAME}\", 'wb').write(r.content)\n",
    "        print('Loaded.')\n",
    "\n",
    "        # All data is now loaded to the Data folder.\n",
    "        \n",
    "        \n",
    "def read_data() -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"read all 3 datasets provided for this task from the xml files\n",
    "    with directory and file names stored in global variables\n",
    "\n",
    "    :returns - tuple with 3 pandas dataframes: A_office, B_office, HR_data\n",
    "    \"\"\"\n",
    "    return pd.read_xml(f\"{DATA_DIR}/{A_FNAME}\"), \\\n",
    "        pd.read_xml(f\"{DATA_DIR}/{B_FNAME}\"), \\\n",
    "        pd.read_xml(f\"{DATA_DIR}/{HR_FNAME}\")\n",
    "\n",
    "\n",
    "def examine_dataframes(*args) -> None:\n",
    "    \"\"\"prints basic information about the dataframe(s) provided\n",
    "\n",
    "    :param - dataframe(s) to examine\n",
    "    :returns - None\n",
    "    \"\"\"\n",
    "    for df in args:\n",
    "        print(SEP)\n",
    "        print(f\"SHAPE: {df.shape}, INFO:\")\n",
    "        print(df.info())\n",
    "        print('---\\nHEAD:')\n",
    "        print(df.head())\n",
    "        print('---\\nTAIL:')\n",
    "        print(df.tail())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e370a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # original code put into the function - just in case of deleting some localy stored data\n",
    "    download_datasets()\n",
    "\n",
    "    # STAGE 1\n",
    "    \"\"\"Goals:\n",
    "        reading dataframes from xml files\n",
    "        working with df indices - changing them using values from the df itself \n",
    "        and some additional data (prefixes 'A'/'B' here)\n",
    "    \"\"\"\n",
    "\n",
    "    # objective 1 - read data\n",
    "    a_office, b_office, hr = read_data()\n",
    "\n",
    "    # objective 2 - examine data\n",
    "\n",
    "    # objective #3 - set indices\n",
    "    a_office.index = a_office.employee_office_id.apply(lambda x: 'A' + str(x))\n",
    "    b_office.index = b_office.apply(lambda row: 'B' + str(row.employee_office_id), axis=1)\n",
    "    hr.set_index(keys='employee_id', drop=False, inplace=True, verify_integrity=True)\n",
    "    \n",
    "    # just 'hr.index = ...' is not enough here because\n",
    "    # it doesn't assign the 'name' to the index as 'set_index' does...\n",
    "    # hr.index = hr.employee_id.values\n",
    "\n",
    "    # objective #4 - print results as lists of indices\n",
    "    # print(a_office.index.tolist())\n",
    "    # print(b_office.index.tolist())\n",
    "    # print(hr.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88536248",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # STAGE 2\n",
    "    \n",
    "    \"\"\"Goals:\n",
    "        joining two df with identical structure with the aim of 'concat'\n",
    "        joining the df with different structure, but indices values present in both df \n",
    "        handling the final df with joined data\n",
    "    \"\"\"\n",
    "    \n",
    "    # objectives #1, #2, #3 - done at Stage #1\n",
    "    # objective #4 - concat A, B\n",
    "    a_b = pd.concat([a_office, b_office])\n",
    "\n",
    "    # objective #5\n",
    "    \"\"\"Use df.merge() to carry out the left merging of the unified office dataset with HR's dataset. \n",
    "        Merge both datasets by index — use left_index and right_index parameters. \n",
    "        Set indicator=True in df.merge(). \n",
    "        For the final table, leave only those employees whose data is contained in both datasets;\n",
    "    \"\"\"\n",
    "    # merge according to the requirements given\n",
    "    a_b_hr = a_b.merge(hr, how='left', left_index=True, right_index=True, indicator=True)\n",
    "\n",
    "    # keep only data taken from both original dataframes\n",
    "    a_b_hr.drop(a_b_hr[a_b_hr._merge != 'both'].index, inplace=True)\n",
    "    \n",
    "    # objective #6\n",
    "    a_b_hr.drop(columns=['employee_office_id', 'employee_id', '_merge'], inplace=True)\n",
    "    \n",
    "    # objective #7\n",
    "    a_b_hr.sort_index(inplace=True)\n",
    "    \n",
    "    # objective #8\n",
    "    # print(new_df.index.to_list())\n",
    "    # print(new_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89c4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # STAGE 3\n",
    "    \n",
    "    \"\"\"Goals:\n",
    "        conditional selection of rows and/or columns from a dataframe\n",
    "        aggregating selected data\n",
    "        converting the df got into list(s)\n",
    "    \"\"\"\n",
    "    \n",
    "    # objectives #1 - #7 - done before\n",
    "    # objective #8 - actuall Stage #3 goals\n",
    "\n",
    "\n",
    "    # objective #8.1\n",
    "    avg_hour_and_dept = a_b_hr[['average_monthly_hours', 'Department']]\n",
    "    avg_hour_and_dept = avg_hour_and_dept.sort_values('average_monthly_hours', ascending=False)\n",
    "    # examine_dataframes(avg_hour_and_dept)\n",
    "    # print(avg_hour_and_dept[0:10]['Department'].tolist())\n",
    "\n",
    "    # objective #8.2\n",
    "    it_emp_low_sal = a_b_hr[(a_b_hr.Department == 'IT') & (a_b_hr.salary == 'low')]\n",
    "    # print(it_emp_low_sal.number_project.sum())\n",
    "\n",
    "    # objective #8.3\n",
    "    # What are the last evaluation scores and the satisfaction levels of the employees A4, B7064, and A3033?\n",
    "    # print([list(row) for row in ABHR.loc[['A4', 'B7064', 'A3033'], ['last_evaluation', 'satisfaction_level']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80b294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # STAGE 4\n",
    "    \n",
    "    \"\"\"Goals:\n",
    "        grouping data and aggregating them with builtin and custom functions\n",
    "    \"\"\"\n",
    "    \n",
    "    # objectives #1 - #7 - done before\n",
    "\n",
    "    # objectives #8 - #10 - actual Stage #3 goals\n",
    "    def count_bigger_5(x):\n",
    "        return sum(x > 5)\n",
    "\n",
    "    # 'left' - column originated from the initial 'hr_data' dataframe\n",
    "    #    = 1.0 if the employee left the company\n",
    "    #    = 0.0 if the employee still works in the company\n",
    "    # the ABHR df has 5982 entries in total, where:\n",
    "    #   'left' == 0.0   - 4570 entries\n",
    "    #   'left' == 1.0   - 1412 entries\n",
    "    \n",
    "    #print(a_b_hr.groupby('left').agg({'number_project':['median', ('count_bigger_5', lambda x: count_bigger_5(x))],\n",
    "    #          'time_spend_company': ['mean', 'median'], 'Work_accident': ['mean'], \n",
    "    #              'last_evaluation': ['mean', 'std']}).round(2))\n",
    "    \n",
    "    # OR\n",
    "    \n",
    "    aggregations_to_satisfy_the_boss = {\n",
    "        'number_project': ['median', count_bigger_5],   # num of proj an employee has worked on\n",
    "        'time_spend_company': ['mean', 'median'],       # how many years worked in the company\n",
    "        'Work_accident': 'mean',                        # wheather has had an injury at work\n",
    "        'last_evaluation': ['mean', 'std']              # last evaluation score\n",
    "    }\n",
    "    # print(ABHR.groupby('left').agg(aggregations_to_satisfy_the_boss).round(2).to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce871fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # STAGE 5\n",
    "    \n",
    "    \"\"\"Goals:\n",
    "        grouping and transforming data with the 'pivot_table' function,\n",
    "        filtering data from the pivot tables\n",
    "        converting pivot tables to dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    # objectives #1 - #7 - done before\n",
    "    # objectives #8 - #11 - actual Stage #5 goals\n",
    "\n",
    "    # objective #8 - from the 'objectives':\n",
    "    #   1st pivot table: Department as index, left and salary as columns,\n",
    "    #   average_monthly_hours as values. Output median values in the table.\n",
    "    \n",
    "    # ovjective #8 - from the description section:\n",
    "    \"\"\"\n",
    "        The first pivot table displays departments as rows, \n",
    "        employees' current status (the 'left' column), and their salary level as columns. \n",
    "        The values should be the median number of monthly hours employees have worked.\n",
    "        (these is done above - see the 'pivot1' df)\n",
    "    \n",
    "        BUT:\n",
    "        In the table, the HR boss wants to see only those departments where either one is true:\n",
    "    \n",
    "        For the currently employed (the 'left' == 0.0): \n",
    "        the median value of the working hours of high-salary employees \n",
    "        is smaller than the hours of the medium-salary employees, \n",
    "    \n",
    "        OR:\n",
    "    \n",
    "        For the employees who left (the 'left' == 1.0): \n",
    "        the median value of working hours of low-salary employees \n",
    "        is smaller than the hours of high-salary employees\n",
    "    \"\"\"\n",
    "    a_b_hr_to_pivot = a_b_hr.copy(deep=True)\n",
    "    \n",
    "    pivoted_1_1 = a_b_hr_to_pivot.pivot_table(values = 'average_monthly_hours', \n",
    "                                  index = 'Department', columns = ['left', 'salary'], aggfunc='median')\n",
    "    pivoted_1_2 = pivoted_1_1.loc[(pivoted_1_1[(0.0, 'high')] < pivoted_1_1[(0.0, 'medium')]) \n",
    "                                  & (pivoted_1_1[(1.0, 'low')] < pivoted_1_1[(1.0, 'high')])]\n",
    "    \n",
    "\n",
    "    # objective #9 - from the 'objectives' section:\n",
    "    \"\"\"\n",
    "        second pivot table:\n",
    "        time_spend_company as index, promotion_last_5years as column,\n",
    "        satisfaction_level and last_evaluation as values.\n",
    "        Output the min, max, and mean values in the table.\n",
    "    \"\"\"\n",
    "    pivoted_2_1 = pd.pivot_table(a_b_hr, values = ['last_evaluation', 'satisfaction_level'], \n",
    "                                       index = 'time_spend_company', columns = ['promotion_last_5years'], \n",
    "                                       aggfunc=['min', 'max', 'mean'])\n",
    "\n",
    "\n",
    "    # ovjective #9 - from the description section:\n",
    "    \"\"\"\n",
    "        The second pivot table is where each row is an employee's time in the company; \n",
    "        the columns indicate whether an employee has had any promotion. \n",
    "        The values are the last evaluation score's minimum, maximum, mean, and satisfaction level. \n",
    "        Filter the table by the following rule: \n",
    "        select only those rows where the previous mean evaluation score \n",
    "        is higher for those without promotion than those who had.\n",
    "    \"\"\"\n",
    "    # objective #10 applied to objective #9:\n",
    "    pivoted_2_2 = pivoted_2_1.loc[pivoted_2_1[('mean', 'last_evaluation', 0)] > pivoted_2_1[('mean', 'last_evaluation', 1)]]\n",
    "\n",
    "    # objective #11:\n",
    "    # print(pivoted_1_1.to_dict())\n",
    "    # print(pivoted_2_2.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f09d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
